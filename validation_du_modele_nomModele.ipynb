{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "equivalent-insured",
   "metadata": {},
   "source": [
    "<div class=\"text_cell_render rendered_html\" tabindex=\"-1\">\n",
    "    <p><img src=\"https://datascientest.fr/train/assets/logo_datascientest.png\" style=\"height: 150px\"></p>\n",
    "    <p></p><hr style=\"border-width: 2px ; border-color: #75dfc1\"><p></p>\n",
    "    <p></p><h1 style=\"text-align: center\" id=\"-Etude-d-un-modèle-\"> Etude d'un modèle <a class=\"anchor-link\" href=\"#-Etude-d-un-modèle-\">¶</a></h1><p></p>\n",
    "    <p></p><h2 style=\"text-align: center\" id=\"-Introduction-\"> Introduction <a class=\"anchor-link\" href=\"#-Introduction-\">¶</a></h2><p></p>\n",
    "    <hr style=\"border-width: 2px ; border-color: #75dfc1\">\n",
    "    <blockquote>\n",
    "        <p>Dans ce note book, on se propose de tester et valider les preformances d'un CNN.</p>\n",
    "        <p>On peut céer un modèle personnalisé en utilisant la fonction model_libre du fichier modelPredefini.py, ou on peut  choisir parmis les modèles du fichier.</p><br><br>\n",
    "        <p>On va tester les performances du modèle sur des images en niveaux de gris, puis en couleur avec 4 classes.</p>\n",
    "    </blockquote>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-howard",
   "metadata": {},
   "source": [
    "# Première Partie - Préparation de l'environnement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-establishment",
   "metadata": {},
   "source": [
    "## 1 - Importation des différentes librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.backend import sigmoid\n",
    "\n",
    "# On importe nos librairies\n",
    "import library.imageFunctions as mylib\n",
    "import library.modelPredefini as mpf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-munich",
   "metadata": {},
   "source": [
    "## 2 - Fonctions d'activation complémentaires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brief-cheat",
   "metadata": {},
   "source": [
    "### a - Fonction d'activation Mish\n",
    "On définit une fonction d'activation pour des tests éventuels. Optionnel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conscious-canberra",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align: left\" id=\"-Courte présentation-\"> Courte présentation <a class=\"anchor-link\" href=\"#-Introduction-\">¶</a></h3>\n",
    "<h6 style=\"text-align: left\" id=\"-Extrait d'article-\"> Extrait d'article : <a class=\"anchor-link\" href=\"#-Introduction-\">¶</a></h6><a href=\"https://penseeartificielle.fr/mish-vs-relu-meilleure-fonction-activation/\" target=\"_blank\" rel=\"noreferrer noopener\" aria-label=\"Arxiv (opens in a new tab)\">Article original</a>.</p>\n",
    "<p>Mish est présentée comme une <em>fonction auto-régularisée, non-monotone</em>. Elle est inspirée des travaux de l’équipe de <strong>Google Brain</strong> qui a créé “<strong>Swish</strong>” en 2017, une autre fonction d’activation légèrement différente (et moins performante, d’où un article sur Mish) ! Mish a été inventée et codée par le mathématicien <strong>Diganta Misra</strong> </p>\n",
    "<p>Voici le graphe de la fonction Mish :</p>\n",
    "<div class=\"wp-block-image\"><figure class=\"aligncenter is-resized\"><img src=\"https://penseeartificielle.fr/wp-content/uploads/2019/10/mish-activation.png\" alt=\"\" class=\"wp-image-2418 td-animation-stack-type0-2\" width=\"334\" height=\"326\" srcset=\"https://penseeartificielle.fr/wp-content/uploads/2019/10/mish-activation.png 579w, https://penseeartificielle.fr/wp-content/uploads/2019/10/mish-activation-300x293.png 300w, https://penseeartificielle.fr/wp-content/uploads/2019/10/mish-activation-430x420.png 430w\" sizes=\"(max-width: 334px) 100vw, 334px\"><figcaption>Graphe de la fonction Mish, qui se rapproche de 0 dans les valeurs négatives et tend vers l’infini dans les valeurs positives (crédit : Diganta Misra)</figcaption></figure></div>\n",
    "<p>Mathématiquement parlant, Mish est une savante combinaison de tangente hyperbolique (vue précédemment), du logarithme népérien (“$ln$”) et de l’exponentielle (“$e$”) :  $mish(x)=x⋅tanh(ln((1+e^{x}))$</p>\n",
    "<p>A noter que  $ln(1+e^{x})$  est souvent appelée fonction “softplus“, transformant la définition de Mish en  $mish(x)=x⋅tanh(softplus(x))$</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-supply",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mish(inputs):\n",
    "    return inputs * tf.math.tanh(tf.math.softplus(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-tokyo",
   "metadata": {},
   "source": [
    "### b - Fonction d'activation switch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-citation",
   "metadata": {},
   "source": [
    "<p>Tout d’abord, <a href=\"https://medium.com/@neuralnets/swish-activation-function-by-google-53e1ea86f820\" target=\"_blank\" rel=\"noreferrer noopener\" aria-label=\"swish  (opens in a new tab)\">swish </a>(qui est β-swish avec β=1) est définie ainsi :</p>\n",
    "<span class=\"MathJax\" id=\"MathJax-Element-6-Frame\" tabindex=\"0\" style=\"\"><nobr><span class=\"math\" id=\"MathJax-Span-124\" style=\"width: 17.544em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 14.374em; height: 0px; font-size: 122%;\"><span style=\"position: absolute; clip: rect(1.26em, 1014.26em, 2.626em, -999.997em); top: -2.183em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-125\"><span class=\"mi\" id=\"MathJax-Span-126\" style=\"font-family: MathJax_Math; font-style: italic;\">β<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mtext\" id=\"MathJax-Span-127\" style=\"font-family: MathJax_Main;\">-swish</span><span class=\"mo\" id=\"MathJax-Span-128\" style=\"font-family: MathJax_Main;\">(</span><span class=\"mi\" id=\"MathJax-Span-129\" style=\"font-family: MathJax_Math; font-style: italic;\">x</span><span class=\"mo\" id=\"MathJax-Span-130\" style=\"font-family: MathJax_Main;\">,</span><span class=\"mi\" id=\"MathJax-Span-131\" style=\"font-family: MathJax_Math; font-style: italic; padding-left: 0.167em;\">β<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-132\" style=\"font-family: MathJax_Main;\">)</span><span class=\"mo\" id=\"MathJax-Span-133\" style=\"font-family: MathJax_Main; padding-left: 0.276em;\">=</span><span class=\"mi\" id=\"MathJax-Span-134\" style=\"font-family: MathJax_Math; font-style: italic; padding-left: 0.276em;\">x</span><span class=\"mo\" id=\"MathJax-Span-135\" style=\"font-family: MathJax_Main; padding-left: 0.221em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-136\" style=\"font-family: MathJax_Math; font-style: italic; padding-left: 0.221em;\">s</span><span class=\"mi\" id=\"MathJax-Span-137\" style=\"font-family: MathJax_Math; font-style: italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-138\" style=\"font-family: MathJax_Math; font-style: italic;\">g<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-139\" style=\"font-family: MathJax_Math; font-style: italic;\">m</span><span class=\"mi\" id=\"MathJax-Span-140\" style=\"font-family: MathJax_Math; font-style: italic;\">o</span><span class=\"mi\" id=\"MathJax-Span-141\" style=\"font-family: MathJax_Math; font-style: italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-142\" style=\"font-family: MathJax_Math; font-style: italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-143\" style=\"font-family: MathJax_Main;\">(</span><span class=\"mi\" id=\"MathJax-Span-144\" style=\"font-family: MathJax_Math; font-style: italic;\">x</span><span class=\"mo\" id=\"MathJax-Span-145\" style=\"font-family: MathJax_Main; padding-left: 0.221em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-146\" style=\"font-family: MathJax_Math; font-style: italic; padding-left: 0.221em;\">β<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-147\" style=\"font-family: MathJax_Main;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.189em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.397em; border-left: 0px solid; width: 0px; height: 1.337em;\"></span></span></nobr></span>\n",
    "<p>Mish et swish donnent quasiment la même courbe, avec quelques différences au niveau de la partie négative (on a une concavité plus importante avec mish) et une pente plus forte de la partie positive pour la fonction mish.</p>\n",
    "<div class=\"wp-block-column\">\n",
    "<div class=\"wp-block-image\"><figure class=\"aligncenter is-resized\"><img src=\"https://penseeartificielle.fr/wp-content/uploads/2019/10/swish-activation.png\" alt=\"\" class=\"wp-image-2419 td-animation-stack-type0-2\" width=\"566\" height=\"146\" srcset=\"https://penseeartificielle.fr/wp-content/uploads/2019/10/swish-activation.png 626w, https://penseeartificielle.fr/wp-content/uploads/2019/10/swish-activation-300x130.png 300w\" sizes=\"(max-width: 283px) 100vw, 283px\"><figcaption>Swish (crédit : Diganta Misra) </figcaption></figure></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-georgia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swish(x, beta = 1):\n",
    "    return (x * sigmoid(beta * x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-sweden",
   "metadata": {},
   "source": [
    "## 3 - Préparation des données pour les tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charitable-charge",
   "metadata": {},
   "source": [
    "### a - Les données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-macedonia",
   "metadata": {},
   "source": [
    "Ici, on commence à préparer les données pours les tests.    \n",
    "On va donc faire une première préparation de base, qui va nous permettre en suite, de créer le jeux pour l'étude sur 4 classes et sur 15 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-three",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Répertoires contenant les images\n",
    "repTrain  = 'train_images/'\n",
    "repTest   = 'test_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-cutting",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Chargement du fichier train.csv\n",
    "train = pd.read_csv('train.csv')\n",
    "\n",
    "## Séparation nom de fichier / label\n",
    "sep = '_'\n",
    "train['image'] = train['Image_Label'].apply(lambda x: x.split(sep)[0])\n",
    "train['label'] = train['Image_Label'].apply(lambda x: x.split(sep)[1])\n",
    "train = train.drop(['Image_Label'], axis=1)\n",
    "\n",
    "## Suppression des labels sans zone identifiées (variable EncodedPixels a NaN)\n",
    "train = train.dropna()\n",
    "\n",
    "## One Hot Encoding des classes de nuages et suprression des variables label et EncodedPixels\n",
    "## On effectue une dichotomisation des classes de nuages\n",
    "train_encoded = train\n",
    "train_encoded= train_encoded.join(pd.get_dummies(train_encoded['label']))\n",
    "\n",
    "## On supprime ensuite les colonnes \"encoded Pixels\" et \"label\", inutiles pour l'aggregation qui suit\n",
    "train_encoded = train_encoded.drop(['EncodedPixels', 'label'], axis=1)\n",
    "\n",
    "## Enfin on fait un sous-total pour ne conserver qu'une ligne par image\n",
    "train_encoded = train_encoded.groupby(['image']).sum()\n",
    "\n",
    "train_encoded = train_encoded.reset_index(level=0)\n",
    "train_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-renaissance",
   "metadata": {},
   "source": [
    "Ici, on peut utiliser train_encoded tel quel, il nous faut juste définir la liste des classes pour la génération d'images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-grocery",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Fish', 'Flower', 'Gravel', 'Sugar']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dangerous-cleaners",
   "metadata": {},
   "source": [
    "Maintenant, on va séparer le jeux en deux. Un pour l'entrainement, et qui sera utilisé dans le générateur et lautre qui ne servira que pour le test du modèle et pour les analysees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-flavor",
   "metadata": {},
   "outputs": [],
   "source": [
    "## On prend 20 % pour le test.\n",
    "## On fixe le random_state à 42 pour utiliser le même jeux de données quelques soit les tests\n",
    "train_encoded_train, train_encoded_test = train_test_split(train_encoded, \n",
    "                                                           test_size = 0.2, \n",
    "                                                           random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crazy-juvenile",
   "metadata": {},
   "source": [
    "# Seconde Partie - Les tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-mechanics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On définit nos variables globales\n",
    "batch_size = 32\n",
    "image_width = 140\n",
    "image_height = 210\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "institutional-drunk",
   "metadata": {},
   "source": [
    "### A - Test en niveaux de gris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-objective",
   "metadata": {},
   "source": [
    "#### A.1. - Génération des images pour l'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-reach",
   "metadata": {},
   "outputs": [],
   "source": [
    "## On appelle la fonction qui génére les jeux\n",
    "train_generator, validation_generator = mylib.image_data_generator(data=train_encoded_train,\n",
    "                                                                  directory=repTrain,\n",
    "                                                                  filename='image',\n",
    "                                                                  classes=classes,\n",
    "                                                                  image_width=image_width,\n",
    "                                                                  image_height=image_height,\n",
    "                                                                  canal=1,\n",
    "                                                                  batch_size=batch_size,\n",
    "                                                                  seed=42)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-locator",
   "metadata": {},
   "outputs": [],
   "source": [
    "## On affiche la premiere image, qui peut changer a chaque execution puisque nous avons effectue un shuffle\n",
    "## La premiere image est affichee ainsi que les augmentations qu'elle a subit\n",
    "augmented_images = [train_generator[0][0][0] for i in range(5)]\n",
    "mylib.plotImages(images_arr=augmented_images,\n",
    "                canal=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mature-england",
   "metadata": {},
   "source": [
    "#### A.2. - Entraînement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-restriction",
   "metadata": {},
   "outputs": [],
   "source": [
    "## On crée le modèle avec des paramètres personnalisés\n",
    "modele_libre = mpf.model_libre(image_width=image_width,\n",
    "                               image_height=image_height,\n",
    "                               nb_classes=4,\n",
    "                               canaux=1,\n",
    "                               coucheConv2D=1,\n",
    "                               coucheDense=1,\n",
    "                               GlobalAveragePooling2D_layer=False,\n",
    "                               nb_filters_start=32,\n",
    "                               kernel_size_start=(3,3),\n",
    "                               activation_start='relu',\n",
    "                               pool_size_start=(2,2),\n",
    "                               padding_start='valid',\n",
    "                               nb_filters=16,\n",
    "                               kernel_size=(3,3),\n",
    "                               pool_size=(2,2),\n",
    "                               padding='valid',\n",
    "                               nb_units=64,\n",
    "                               activation='relu',\n",
    "                               coeff_drop=0.2,\n",
    "                               activation_sortie='sigmoid',\n",
    "                               affichage = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-swedish",
   "metadata": {},
   "outputs": [],
   "source": [
    "## On compile le modèle\n",
    "lr = 1e-3\n",
    "modele_libre.compile(optimizer=Adam(lr), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-plane",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On crée nos callback \n",
    "checkpoint = mpf.checkpoint_function(filepath=f\"checkpoint/weights_modele_libre.hdf5\")\n",
    "lr_plateau = mpf.reduceLR_function()\n",
    "e_stopping = mpf.estopping_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subjective-pharmacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On entraine le modèle sur 50 époques\n",
    "EPOCHS = 100\n",
    "STEP_SIZE_TRAIN=train_generator.n//batch_size\n",
    "STEP_SIZE_VALID=validation_generator.n//batch_size\n",
    "\n",
    "history = modele_libre.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=STEP_SIZE_VALID,\n",
    "    callbacks=[lr_plateau, checkpoint, e_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dangerous-front",
   "metadata": {},
   "source": [
    "#### A.3. - Evaluation du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imperial-toyota",
   "metadata": {},
   "source": [
    "On commence par afficher les courbes d'évolution de l'accuracy et de la loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-employment",
   "metadata": {},
   "outputs": [],
   "source": [
    "## On fait appel à la fonction qui affiche la=es courbess.\n",
    "epochTrain = len(history.history['loss'])\n",
    "mylib.affiche_resultat(history, epochTrain, len(classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excellent-consideration",
   "metadata": {},
   "source": [
    "Maintenant, on va faire une prédiction sur le jeux de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-hardwood",
   "metadata": {},
   "outputs": [],
   "source": [
    "## On prépare le jeux de test avec la fonction convert_image(X, canaux, repPath):\n",
    "X_test = train_encoded_test['image']\n",
    "y_test = train_encoded_test[classes]\n",
    "\n",
    "X_test_img = mylib.convert_image(data=X_test,\n",
    "                                 image_width=image_width,\n",
    "                                 image_height=image_height,\n",
    "                                 canaux=1, \n",
    "                                 repPath=repTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-interest",
   "metadata": {},
   "outputs": [],
   "source": [
    "## On fait des prédictions\n",
    "y_pred = modele_libre.predict(X_test_img).round()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-camel",
   "metadata": {},
   "outputs": [],
   "source": [
    "## On affiche le rpport de classification\n",
    "print(classification_report(y_test, y_pred, target_names = classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-click",
   "metadata": {},
   "outputs": [],
   "source": [
    "## On affiche le score et la loss du modèle\n",
    "scores = modele_libre.evaluate(X_test_img, y_test, verbose=0)\n",
    "print(\"%s: %.2f\" % (modele_libre.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (modele_libre.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "center-status",
   "metadata": {},
   "outputs": [],
   "source": [
    "##On affiche la table de confusion\n",
    "## Pour afficher la matrice de confusion on transforme y_pred\n",
    "y_pred_df = pd.DataFrame(y_pred, index = y_test.index, columns = classes)\n",
    "\n",
    "### Affichage de la matrice de confusion avec multilabel_confusion_matrix\n",
    "cnf_matrix = multilabel_confusion_matrix(y_test, y_pred_df)\n",
    "print(cnf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-sharp",
   "metadata": {},
   "source": [
    "### B - Test en couleurs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amended-density",
   "metadata": {},
   "source": [
    "#### B.1. - Génération des images pour l'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greater-connecticut",
   "metadata": {},
   "outputs": [],
   "source": [
    "## On appelle la fonction qui génére les jeux\n",
    "train_generator, validation_generator = mylib.image_data_generator(data=train_encoded_train,\n",
    "                                                                  directory=repTrain,\n",
    "                                                                  filename='image',\n",
    "                                                                  classes=classes,\n",
    "                                                                  image_width=image_width,\n",
    "                                                                  image_height=image_height,\n",
    "                                                                  canal=3,\n",
    "                                                                  batch_size=batch_size,\n",
    "                                                                  seed=42)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-basics",
   "metadata": {},
   "outputs": [],
   "source": [
    "## On affiche la premiere image, qui peut changer a chaque execution puisque nous avons effectue un shuffle\n",
    "## La premiere image est affichee ainsi que les augmentations qu'elle a subit\n",
    "augmented_images = [train_generator[0][0][0] for i in range(5)]\n",
    "mylib.plotImages(augmented_images, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "activated-mongolia",
   "metadata": {},
   "source": [
    "#### B.2. - Entraînement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-replication",
   "metadata": {},
   "outputs": [],
   "source": [
    "## On crée le modèle avec des paramètres personnalisés\n",
    "modele_libre_color = mpf.model_libre(image_width=image_width,\n",
    "                               image_height=image_height,\n",
    "                               nb_classes=4,\n",
    "                               canaux=3,\n",
    "                               coucheConv2D=1,\n",
    "                               coucheDense=1,\n",
    "                               GlobalAveragePooling2D_layer=False,\n",
    "                               nb_filters_start=32,\n",
    "                               kernel_size_start=(3,3),\n",
    "                               activation_start='relu',\n",
    "                               pool_size_start=(2,2),\n",
    "                               padding_start='valid',\n",
    "                               nb_filters=16,\n",
    "                               kernel_size=(3,3),\n",
    "                               pool_size=(2,2),\n",
    "                               padding='valid',\n",
    "                               nb_units=64,\n",
    "                               activation='relu',\n",
    "                               coeff_drop=0.2,\n",
    "                               activation_sortie='sigmoid',\n",
    "                               affichage = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-edmonton",
   "metadata": {},
   "outputs": [],
   "source": [
    "## On compile le modèle\n",
    "lr = 1e-3\n",
    "modele_libre_color.compile(optimizer=Adam(lr), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-improvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On crée nos callback \n",
    "checkpoint = mpf.checkpoint_function(filepath=f\"checkpoint/weights_modele_libre_color.hdf5\")\n",
    "lr_plateau = mpf.reduceLR_function()\n",
    "e_stopping = mpf.estopping_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sweet-chamber",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On définit la variable contenant le chemin de sauvegarde du modèle\n",
    "checkpointPath = 'checkpoint/modele_libre_color'\n",
    "\n",
    "# On entraine le modèle sur 50 époques\n",
    "EPOCHS = 100\n",
    "STEP_SIZE_TRAIN=train_generator.n//batch_size\n",
    "STEP_SIZE_VALID=validation_generator.n//batch_size\n",
    "\n",
    "history = modele_libre_color.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=STEP_SIZE_VALID,\n",
    "    callbacks=[lr_plateau, checkpoint, e_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arabic-steering",
   "metadata": {},
   "source": [
    "#### B.3. - Evaluation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-particle",
   "metadata": {},
   "outputs": [],
   "source": [
    "## On fait appel à la fonction qui affiche la=es courbess.\n",
    "epochTrain = len(history.history['loss'])\n",
    "mylib.affiche_resultat(history, epochTrain, len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-internet",
   "metadata": {},
   "outputs": [],
   "source": [
    "## On prépare le jeux de test avec la fonction convert_image(X, canaux, repPath):\n",
    "X_test = train_encoded_test['image']\n",
    "y_test = train_encoded_test[classes]\n",
    "\n",
    "X_test_img_color = mylib.convert_image(data=X_test,\n",
    "                                 image_width=image_width,\n",
    "                                 image_height=image_height,\n",
    "                                 canaux=3, \n",
    "                                 repPath=repTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-spain",
   "metadata": {},
   "outputs": [],
   "source": [
    "## On fait des prédictions\n",
    "y_pred_color = modele_libre_color.predict(X_test_img_color).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-hunger",
   "metadata": {},
   "outputs": [],
   "source": [
    "## On affiche le rpport de classification\n",
    "print(classification_report(y_test, y_pred_color, target_names = classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-parish",
   "metadata": {},
   "outputs": [],
   "source": [
    "## On affiche le score et la loss du modèle\n",
    "scores = modele_libre_color.evaluate(X_test_img_color, y_test, verbose=0)\n",
    "print(\"%s: %.2f\" % (modele_libre_color.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (modele_libre_color.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-ferry",
   "metadata": {},
   "outputs": [],
   "source": [
    "##On affiche la table de confusion\n",
    "## Pour afficher la matrice de confusion on transforme y_pred\n",
    "y_pred_color_df = pd.DataFrame(y_pred_color, index = y_test.index, columns = classes)\n",
    "\n",
    "### Affichage de la matrice de confusion avec multilabel_confusion_matrix\n",
    "cnf_matrix = multilabel_confusion_matrix(y_test, y_pred_color_df)\n",
    "print(cnf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
